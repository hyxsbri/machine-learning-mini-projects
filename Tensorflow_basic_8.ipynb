{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02449263",
   "metadata": {},
   "source": [
    "- 함수형 API (Functional API) -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395a585",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "967be7de",
   "metadata": {},
   "source": [
    "Sequential API - 입력부터 출력까지 일직선으로 연결, 직관적으로 편리함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63161cbb",
   "metadata": {},
   "source": [
    "Functional API - 여러개의 층 공유, 다양한 종류의 입출력 등 일직선 구조 한계를 보완해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0985d5",
   "metadata": {},
   "source": [
    "example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f76f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,058\n",
      "Trainable params: 1,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential API 를 Functional API 로 구현\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_ = Input(shape = (4,))\n",
    "\n",
    "x = Dense(8, activation = 'relu')(input_)\n",
    "x = Dense(16, activation = 'relu')(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "\n",
    "output_ = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "md = Model(inputs = input_, outputs = output_)\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe346f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 8)            40          ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           144         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 8)            72          ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 24)           0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 10)           250         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 506\n",
      "Trainable params: 506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 다중 입력 in Functional API\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "#입력층 1에 대한 신경망\n",
    "input1 = Input(shape = (4,))\n",
    "\n",
    "hidden1 = Dense(8, activation = 'relu')(input1)\n",
    "hidden2 = Dense(16, activation = 'relu')(hidden1)\n",
    "\n",
    "output1 = Model(inputs = input1, outputs = hidden2)\n",
    "\n",
    "#입력층 2에 대한 신경망\n",
    "input2 = Input(shape = (8,))\n",
    "\n",
    "hidden3 = Dense(8, activation = 'relu')(input2)\n",
    "\n",
    "output2 = Model(inputs = input2, outputs = hidden3)\n",
    "\n",
    "#층 연결\n",
    "result = concatenate([output1.output, output2.output])\n",
    "\n",
    "#출력층 정의\n",
    "output = Dense(10, activation = 'softmax')(result)\n",
    "\n",
    "#최종 모델 구축\n",
    "md = Model(inputs = [output1.input, output2.input], outputs = output)\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b63d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "716e6aa0",
   "metadata": {},
   "source": [
    "MNIST CNN modeling exmple in Functional API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0504510c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112aafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "(xtr, ytr), (xt, yt) = mnist.load_data()\n",
    "\n",
    "xtr = xtr.reshape(-1, 28,28, 1)\n",
    "xt = xt.reshape(-1, 28, 28, 1)\n",
    "\n",
    "xtr = xtr / 255.0\n",
    "xt = xt / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b32809",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape = (28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, 3, activation = 'relu')(input_)\n",
    "x = Conv2D(64, 3, activation = 'relu')(x)\n",
    "x = MaxPool2D(pool_size = (2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output_ = Dense(10, activation = 'softmax')(x)\n",
    "cnn = Model(inputs = input_, outputs = output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d372fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 모델 컴파일 및 학습\n",
    "\n",
    "cnn.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(),\\\n",
    "           metrics = ['accuracy'])\n",
    "\n",
    "hist = cnn.fit(xtr, ytr, batch_size = 128, epochs = 30, validation_data = (xt, yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80e45c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d72b37",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad662e3",
   "metadata": {},
   "source": [
    "- 전이 학습(Transfer Learning) -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b4dc8",
   "metadata": {},
   "source": [
    "부족한 학습 데이터 문제를 해결하기 위해 등장,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0d6f0",
   "metadata": {},
   "source": [
    "ImageNet 데이터를 활용해 학습된 모델의 가중치를 가져와서, 해결하려는 문제에 맞게 보정해서 사용하는 개념,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566da6c",
   "metadata": {},
   "source": [
    "사전 학습 모델(pre-trained model) : 큰 데이터셋을 사용해 훈련된 모델."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd723437",
   "metadata": {},
   "source": [
    "사전 학습 모델의 구조 : 사전 학습된 feature extractor / 사전 학습된 classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68289c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c3134d",
   "metadata": {},
   "source": [
    "파인 튜닝(fine - tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80a0a9",
   "metadata": {},
   "source": [
    "사전 학습 모델의 가중치를 미세하게 조정하는 기법,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a1fa8",
   "metadata": {},
   "source": [
    "많은 연산량으로 인해 CPU 보다는 GPU 를 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75310e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e55b04d",
   "metadata": {},
   "source": [
    "transfer learning 활용법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bdac455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 240, 240, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 240, 240, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 240, 240, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 120, 120, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 120, 120, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 120, 120, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 60, 60, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 60, 60, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 60, 60, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 60, 60, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNet, InceptionV3\n",
    "#tensorflow 에서 제공하는 다양한 사전학습 모델 import\n",
    "\n",
    "base_md = VGG16(weights = 'imagenet', include_top = False, input_shape = (240, 240, 3))\n",
    "#input_shape = (widths, heights, channel)\n",
    "#include_top = False : 특징 추출기만 가져옴, True : 특징 추출기와 분류기 모두 가져옴.\n",
    "base_md.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b838849",
   "metadata": {},
   "source": [
    "include_top = False 지정하여, conv2D 와 Maxpooling 으로 구성된 특징 추출기만 가져온 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5cb3030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                1605696   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,320,644\n",
      "Trainable params: 16,320,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "md = Sequential()\n",
    "md.add(base_md)\n",
    "#pre_trained model\n",
    "md.add(Flatten())\n",
    "#Flatten - 텐서를 1차원 벡터로 변환시켜줌, 사전 학습된 특징 추출기와 분류기를 연결시켜주는 역할\n",
    "md.add(Dense(64, activation = 'relu'))\n",
    "md.add(Dropout(0.25))\n",
    "md.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "md.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(),\\\n",
    "          metrics = ['accuracy'])\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864602f1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea77b7",
   "metadata": {},
   "source": [
    "- 전이 학습 예제(Cats and Dogs) -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec17010",
   "metadata": {},
   "source": [
    "Cats and Dogs Dataset : CNN 아키텍쳐 구축 및 평가를 위한 기본 학습 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03345923",
   "metadata": {},
   "source": [
    "2000 개의 학습 데이터, 1000 개의 테스트 데이터로 구성, 학습 데이터가 부족하기 때문에 전이 학습을 활용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83962028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tuning using pre-trained model(Xception)\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "#사전 학습 모델 import\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Cats and Dogs 데이터셋 압축풀기\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('cats_and_dogs_filtered.zip', 'r') as target_file:\n",
    "\n",
    "    target_file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41cc1ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                32784     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,894,298\n",
      "Trainable params: 20,839,770\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델링(pre-trained Xception + User-Defined Classifier)\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "base_md = Xception(weights = 'imagenet', include_top = False, input_shape = (img_width, img_height, 3))\n",
    "#사전 학습 모델의 feature extractor 만 사용(include_top = False)\n",
    "\n",
    "md = Sequential()\n",
    "\n",
    "md.add(base_md)\n",
    "\n",
    "md.add(GlobalAveragePooling2D())\n",
    "#------------------------------------------- User-Defined Classifier(아래)\n",
    "md.add(Dense(16, activation = 'relu'))\n",
    "md.add(Dropout(0.25))\n",
    "\n",
    "md.add(Dense(2, activation = 'softmax'))\n",
    "#정답은 고양이 또는 개, 총 두개이므로 출력층 노드 : 2\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c7f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator 정의\n",
    "\n",
    "train_dir = './cats_and_dogs_filtered/train'\n",
    "test_dir = './cats_and_dogs_filtered/validation'\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale = 1./ 255, \n",
    "                                    rotation_range = 10, width_shift_range = 0.1, \n",
    "                                    height_shift_range = 0.1, shear_range = 0.1, zoom_range = 0.1)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "#이미지 데이터 읽어올 때, 자동으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c9ba97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data_gen.flow_from_directory(train_dir, batch_size = 32, \n",
    "                                                color_mode = 'rgb', shuffle = True, class_mode = 'categorical',\n",
    "                                                target_size = (img_width,img_height))\n",
    "\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(test_dir, batch_size = 32, \n",
    "                                              color_mode = 'rgb', shuffle = True, class_mode = 'categorical',\n",
    "                                              target_size = (img_width,img_height))\n",
    "\n",
    "#class_mode = 'categorical' : 정답은 원핫 인코딩으로 정의됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6554eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('cats', 0), ('dogs', 1)])\n",
      "dict_items([('cats', 0), ('dogs', 1)])\n"
     ]
    }
   ],
   "source": [
    "#정답 확인\n",
    "\n",
    "print(train_data.class_indices.items())\n",
    "print(test_data.class_indices.items())\n",
    "#class_indices : 문자열로 표시되는 데이터 정답이 어떤 숫자로 매칭되는지 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일 및 학습\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "md.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(2e-5),\\\n",
    "          metrics = ['accuracy'])\n",
    "#fine-tuning : 학습률을 낮게 설정해 pre-trained 가중치를 조금씩 업데이트 해주는 것이 핵심,\n",
    "\n",
    "save_file_name = './cats_and_dogs_Xception'\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_file_name, monitor = 'val_loss',\\\n",
    "                            verbose = 1, save_best_only = True, mode = 'auto')\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "\n",
    "hist = md.fit(train_data, epochs = 30, validation_data = test_data, callbacks = [checkpoint, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4417d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa53b827",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb15f61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bf8185",
   "metadata": {},
   "source": [
    "Callback Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373d0ff",
   "metadata": {},
   "source": [
    "특정 상황에서 실행되는 함수를 시스템에 등록 -> 해당 상황이 발생됐을 때, 등록된 함수가 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ea97a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7322a2c6",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau - 학습 중에 학습률 변화시킬 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5,\n",
    "                            #val_loss 기준으로 callback 출력 #callback 호출시, 학습률을 1/2 줄임\n",
    "                            patience = 5, verbose = 1)\n",
    "                            #epoch 5 동안 개선되지 않으면 callback 호출, 로그 출력\n",
    "\n",
    "hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [reduceLR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec423faf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3a91b5",
   "metadata": {},
   "source": [
    "ModelCheckpoint - 모델 가중치를 중간에 저장할 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6656f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = Modelcheckpoint(file_path, monitor = 'val_loss', verbose = 1,\n",
    "                            #val_loss 값이 개선됐을 때 호출, 로그 출력\n",
    "                            save_best_only = True, mode = 'auto')\n",
    "                            #best 값만 저장, 자동으로 best 값을 찾음.\n",
    "                          \n",
    "\n",
    "hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5267e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a89724",
   "metadata": {},
   "source": [
    "EarlyStopping - 모델 성능지표가 일정 시간 개선되지 않을 때 조기 종료시킬 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b538e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = Modelcheckpoint(file_path, monitor = 'val_loss', verbose = 1,\n",
    "                            #val_loss 값이 개선됐을 때 호출, 로그 출력\n",
    "                            save_best_only = True, mode = 'auto')\n",
    "                            #best 값만 저장, 자동으로 best 값을 찾음.\n",
    "    \n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "                  #관찰 대상은 val_loss, epochs = 5 동안 개선되지 않으면 학습 종료\n",
    "                          \n",
    "\n",
    "hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [checkpoint, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca9aec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
